---
output:
  md_document:
    variant: markdown_github
---

# Purpose

Purpose of this work folder.

Ideally store a minimum working example data set in data folder.

Add binary files in bin, and closed R functions in code. Human Readable settings files (e.g. csv) should be placed in settings/


```{r}

rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.
library(tidyverse)
library(lubridate)
library(RColorBrewer)
library(kableExtra)
list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
#this line of code is used to execute any functions I've made that are in the code folder
```


```{r loading data}
Lst_matches <- 
    list.files("data/Tennis/", full.names = T) %>% 
    .[grepl("atp_matches", .)] %>% 
    .[!grepl("doubles|qual|amateur", .)] %>% as.list()

playerinfo <-
        read_csv("data/Tennis/atp_players.csv") %>% select(player_id, hand, height)

# I want to only look at Grandslams, Masters and Finals - use Tournament_Inputs to filter.
suppressWarnings(result_Large_events <- Data_Prep_Function(Lst, Tournament_Inputs = c("G", "M", "F")))

Lst_rankings <- list.files("data/Tennis/", full.names = T) %>% 
    .[grepl("atp_rankings", .)] %>% as.list()
rankings <- Ranking_Prep_Function(Lst_rankings) %>% group_by(year = lubridate::year(date)) %>% filter(date == max(date))
```
This data shows all the stats since the start of the Open Era of tennis (1968, when it became professional) for the main tournaments (Grand Slams, Masters and Tour Finals) as well as the year end top 20 rankings from the 1970s to 2021.

Descriptive stats
I want to look at some stats through time - so maybe grouped into decades who won the most Grand Slams or finished world number 1 etc. But then i can show how since the 2000s, the game has been dominated by the Big 3 and so I can focus on them. It would also be nice to include something about the new guys - Alcaraz, Ruud, Zverev, Tsitsipas etc. This can all be part of my introductory statistics and then the model will be for the Big 3. 

The grouping into decades thing didn't work as well as I would have liked so let me rather just explain things over time through research as then focus on doing stats for the current guys.

```{r}
finals <- result_Large_events %>% filter(round == "F")

frequent_winners <- finals %>% filter(tourney_level == "G") %>% 
  mutate(decade = floor_date(date, "10 years")) %>%
  group_by(decade, winner_name) %>%
  summarize(winner_count = n()) %>%
  top_n(1, winner_count) %>%
  arrange(decade, desc(winner_count)) 






#ggplot(frequent_winners, aes(fill=winner_name, y=winner_count, x=winner_name)) + 
    #geom_bar(position="dodge", stat="identity") +
    #ggtitle("Top Grand Slam Winners per Decade") +
    #theme_bw() +
    #facet_wrap(~decade) +
    #theme(legend.position="none") +
    #xlab("")
```
```{r}
bar_top <- top_GS(finals)
bar_top
```

```{r}
#table <- current_winners(finals)
#table
```
```{r}
table2 <- current_winners_GS(finals)
table2
```
```{r}
df <- finals %>% filter(year(date) >= 2000) %>% filter(tourney_level == "G") %>%
        select(c("date", "tourney_name", "winner_name"))

df$year <- year(as.Date(df$date))

pivot_table <- df %>% group_by (year) %>% pivot_wider(
        names_from = tourney_name,
        values_from = winner_name
    )

pivot_table$date <- NULL

pivot_table <- pivot_table[, -ncol(pivot_table)]
pivot_table$year <- as.character(pivot_table$year)
filterW <- pivot_table %>% filter(!is.na(Wimbledon)) %>% select(c(Wimbledon))

filterR <- pivot_table %>% filter(!is.na(`Roland Garros`)) %>% select(c(`Roland Garros`))

filterUS <- pivot_table %>% filter(!is.na(`US Open`)) %>% select(c(`US Open`))

filterA <- pivot_table %>% filter(!is.na(`Australian Open`)) %>% select(c(`Australian Open`))

merged_df <- merge(merge(merge(filterA, filterR, by = "year"), filterW, by = "year"), filterUS, by = "year")

merged_df

# Fill the NAs with empty strings
pivot_table <- pivot_table %>% fill(everything(), .direction = "down")

# Remove duplicate rows
pivot_table <- distinct(pivot_table, .keep_all = TRUE)
```



I still need to fix the code in the GS_Table function so that it produces a table but basically, that shows how Federer, Nadal and Djokovic have dominated since 2003, when Federer won his first Grand Slam. 
I'm therefore going to filter the data to include only start at 2003 and I'll use this data frame for my model. I've also filtered out some of the other columns that either don't matter or have NAs.
```{r}
model_data <- model_prep(result_Large_events) 

#I need to assign numerical values to my tournament names
model_data <- separate(model_data, tourney_id, into = c("year", "tournament_id"), sep = "-")
model_data <- model_data %>% select(-year)

model_data <- model_data %>%
  mutate(tournament_id = ifelse(tournament_id == "M006", "404", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "M007", "403", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "0410", "410", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "M021", "1536", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "M009", "416", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "0421", "421", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "M024", "422", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "0352", "352", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "0605", "605", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "0403", "403", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "0404", "404", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "0416", "416", tournament_id)) %>% 
    mutate(tournament_id = ifelse(tournament_id == "0422", "422", tournament_id))

tournament_id <- model_data %>% select(tourney_name, tournament_id) %>% distinct(tourney_name, tournament_id)

#This assigns the player IDs
winner_id <- model_data %>% select(winner_name, winner_id) 
winner_id <- winner_id %>% rename(name = winner_name, player_id = winner_id)
loser_id <- model_data %>% select(loser_name, loser_id)
loser_id <- loser_id %>% rename(name = loser_name, player_id = loser_id)
player_id <- merge(winner_id, loser_id, by = "player_id") 
player_id <- player_id %>% distinct(player_id, name.x, name.y) %>% select(-name.y)

#Lastly, I need to assign numerical values to my surfaces and then I'm good to go
model_data <- model_data %>%
  mutate(surface_number = as.integer(as.factor(surface)))
surfaces <- model_data %>% select(surface, surface_number) %>% distinct(surface, surface_number)

#Now to the actual model data frame


model <- model_data %>% select(tournament_id, surface_number, minutes, Player1, Player2, Player1_Rank, Player2_Rank, 
                         Player1_ht, Player2_ht, Player1_age, Player2_age, Player1_1stin, Player2_1stin, Player1_ace, Player2_ace,
                         Player1_bpSaved, Player2_bpSaved, Player1_bpFaced, Player2_bpFaced, Match_Winner)
GS <- model_data %>% filter(tourney_level == "G")
#I've taken out tourney_level in my model_data so I'll just have to change that if I want to subset by Grand Slam
#I've also removed round which I need to take into account if I want to subset by finals

model$Player1_age <- round(model$Player1_age)
model$Player2_age <- round(model$Player2_age)
```

Now onto the actual machine learning model
```{r random forest}
install.packages("ranger")
install.packages("h2o")

library(ranger)   # a c++ implementation of random forest 
library(h2o)      # a java-based implementation of random forest

```
Model beginnings
Need p x 10 trees to start off with
p is the number of features (i.e. variables), which in my case is 20 
p=200

I've got a classification problem so m(try) = squareroot(p)
m(try) = 4 

node size = 1 (can increase this if computational time is too long)

Can try sampling without replacement vs with to see which is better - I probably have unbalanced categories so without might be better.
Decreasing the sample size leads to more diverse trees and thereby lower between-tree correlation, which can have a positive effect on the prediction accuracy. Consequently, if there are a few dominating features in your data set, reducing the sample size can also help to minimize between-tree correlation.

```{r default model}
set.seed(123)  # Set seed for reproducibility
train_indices <- sample(1:nrow(model), 0.7 * nrow(model)) #training set 70% and testing set 30%
train_data <- model[train_indices, ]
test_data <- model[-train_indices, ]

model_rf1 <- ranger(Match_Winner ~ ., data = train_data)
model_rf1
(default_rmse <- sqrt(model_rf1$prediction.error))

predictions_rf1 <- predict(model_rf1, data = test_data)$predictions

test_data$predicted_winner <- predictions_rf1
player_wins <- aggregate(predicted_winner ~ Player1, data = test_data, FUN = sum)
```
According to the default model, the top 3 players are Nadal, Federer and Djokovic in that order



Confusion matrix
I could also create another model that just looks at Grand Slams to see if there's a difference. Especially because Grand Slams are the metric a lot of people use to determine who's the best.
Should I subset by finals too?








